{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce755844-44f1-4e8a-bc0d-b49874125b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.19.0.6 172.18.0.2 \n"
     ]
    }
   ],
   "source": [
    "!hostname -I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b34a4c-bf85-4cba-986e-f082ba89e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257cab67-4330-40db-ad67-eec3ab5a0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae94c597-3412-490e-9bd3-98dbe91849a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                 Apache License\n",
      "                           Version 2.0, January 2004\n",
      "                        http://www.apache.org/licenses/\n",
      "\n",
      "   TERMS AND CONDITIONS FOR USE, REPRODUC\n"
     ]
    }
   ],
   "source": [
    "user = \"hadoop\"\n",
    "host = \"http://namenode:9870\"\n",
    "path = \"/user/hadoop/LICENSE.txt\"\n",
    "hdfs = InsecureClient(host, user)\n",
    "with hdfs.read(path, encoding='utf-8') as reader:\n",
    "    text = reader.read()\n",
    "print(text[:200])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96beca9-6c7a-4bd4-b1ea-3b7df0358acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache     1\n",
      "License     1\n",
      "Version     1\n",
      "2.0,     1\n",
      "January     1\n",
      "2004     1\n",
      "http://www.apache.org/licenses/     1\n",
      "TERMS     1\n",
      "AND     1\n",
      "CONDITIONS     1\n",
      "FOR     1\n",
      "USE,     1\n",
      "REPRODUC     1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "words = text[:200].strip().split()\n",
    "word_counts = Counter(words)\n",
    "# print(word_counts)\n",
    "for word, count in word_counts.items():\n",
    "    print(word,\"   \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3469f2af-6597-4213-b0ce-13d20cc78d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월분기연간인구동향_출생_2025.csv\n",
      "LICENSE.txt\n"
     ]
    }
   ],
   "source": [
    "# 경로내 파일 읽어오기\n",
    "hdfs_dir ='/user/hadoop'\n",
    "show = hdfs.list(hdfs_dir)\n",
    "for s in show:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfa93cd-e01a-43ee-b713-b031222be889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pkdata/data/Note_s1\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625e418c-0d8f-4cb9-ae81-dac9e4286fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 파일 업로드\n",
    "local_path = '../ref/starbucks_20250411113937.csv'\n",
    "hdfs_path = '/user/hadoop/starbucks2.csv'\n",
    "hdfs.upload(hdfs_path, local_path, overwrite = True )\n",
    "print(\"업로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b74f09-cf70-432b-b241-f9e42aa4cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessTime': 0, 'blockSize': 0, 'childrenNum': 3, 'fileId': 16387, 'group': 'supergroup', 'length': 0, 'modificationTime': 1744786983260, 'owner': 'hadoop', 'pathSuffix': '', 'permission': '777', 'replication': 0, 'storagePolicy': 0, 'type': 'DIRECTORY'}\n"
     ]
    }
   ],
   "source": [
    "# 파일 확인\n",
    "hdfs_path = '/user/hadoop/'\n",
    "file_name = 'starbucks2.csv'\n",
    "check = hdfs_path + file_name\n",
    "if hdfs.status(check, strict=False)==None:\n",
    "    print(f\"{check}의 파일이 없습니다.\")\n",
    "else:\n",
    "    print(hdfs.status(hdfs_path, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c8a789-1832-40f0-9294-180e6a5c3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = '/user/hadoop/'\n",
    "del_file = 'starbucks2.csv'\n",
    "full_path = hdfs_path + del_file\n",
    "if hdfs.delete(full_path):\n",
    "    print(\"삭제되었습니다.\")\n",
    "else:\n",
    "    if hdfs.status(full_path, strict=False)==None:\n",
    "        print(f\"{full_path} 파일이 없습니다.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292e4c1-642c-45ff-b4d9-2abfb3a2c6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554736a6-7ed6-4ffc-beb6-e119d1b2690d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
