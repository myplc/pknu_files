get_ipython().getoutput("hostname -I")


# !pip install hdfs


from hdfs import InsecureClient


user = "hadoop"
host = "http://namenode:9870"
path = "/user/hadoop/LICENSE.txt"
hdfs = InsecureClient(host, user)
with hdfs.read(path, encoding='utf-8') as reader:
    text = reader.read()
print(text[:200])   


from collections import Counter
 
words = text[:200].strip().split()
word_counts = Counter(words)
# print(word_counts)
for word, count in word_counts.items():
    print(word,"   ",count)


# 경로내 파일 읽어오기
hdfs_dir ='/user/hadoop'
show = hdfs.list(hdfs_dir)
for s in show:
    print(s)


get_ipython().getoutput("pwd")


# 파일 업로드
local_path = '../ref/starbucks_20250411113937.csv'
hdfs_path = '/user/hadoop/starbucks2.csv'
hdfs.upload(hdfs_path, local_path, overwrite = True )
print("업로드 완료")


# 파일 확인
hdfs_path = '/user/hadoop/'
file_name = 'starbucks2.csv'
check = hdfs_path + file_name
if hdfs.status(check, strict=False)==None:
    print(f"{check}의 파일이 없습니다.")
else:
    print(hdfs.status(hdfs_path, strict=False))


hdfs_path = '/user/hadoop/'
del_file = 'starbucks2.csv'
full_path = hdfs_path + del_file
if hdfs.delete(full_path):
    print("삭제되었습니다.")
else:
    if hdfs.status(full_path, strict=False)==None:
        print(f"{full_path} 파일이 없습니다.")    






